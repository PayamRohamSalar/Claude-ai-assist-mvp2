#!/usr/bin/env python3
"""
Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú©ÛŒÙÛŒØª Ø³ÛŒØ³ØªÙ… RAG
RAG Quality Evaluation System

Ø§ÛŒÙ† Ù…Ø§Ú˜ÙˆÙ„ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú©ÛŒÙÛŒØª Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§ Ùˆ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¬Ø³ØªØ¬Ùˆ Ø±Ø§ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ¯Ù‡Ø¯
This module performs embedding quality assessment and retrieval performance evaluation
"""

import json
import logging
import os
import random
import time
from datetime import datetime, timezone
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple, Union
import numpy as np
from collections import defaultdict, Counter

# Optional imports for backends
try:
    import faiss
    HAS_FAISS = True
except ImportError:
    HAS_FAISS = False

try:
    import chromadb
    from chromadb.config import Settings
    HAS_CHROMA = True
except ImportError:
    HAS_CHROMA = False

try:
    from sentence_transformers import SentenceTransformer
    HAS_SENTENCE_TRANSFORMERS = True
except ImportError:
    HAS_SENTENCE_TRANSFORMERS = False

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('quality_eval.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class QualityEvaluator:
    """
    Ú©Ù„Ø§Ø³ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú©ÛŒÙÛŒØª Ø³ÛŒØ³ØªÙ… RAG
    RAG System Quality Evaluator Class
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ Ú©ÛŒÙÛŒØª
        Initialize quality evaluator
        
        Args:
            config: Dictionary containing configuration parameters
        """
        self.config = config
        self.rag_config = config.get('rag', {})
        
        # Set random seed for deterministic sampling
        self.random_seed = config.get('random_seed', 42)
        random.seed(self.random_seed)
        np.random.seed(self.random_seed)
        
        # Backend configuration
        self.backend = self.rag_config.get('index_backend', 'faiss').lower()
        
        # Model configuration
        self.model_name = self.rag_config.get('embedding_model', 'paraphrase-multilingual-MiniLM-L12-v2')
        
        # Paths
        self.embeddings_path = Path("data/processed_phase_3/embeddings.npy")
        self.meta_path = Path("data/processed_phase_3/embeddings_meta.json")
        self.chunks_path = Path("data/processed_phase_3/chunks.json")
        self.vector_db_dir = Path("data/processed_phase_3/vector_db")
        
        # Output paths
        self.output_dir = Path(".")
        self.embedding_report_path = self.output_dir / "embedding_report.json"
        self.retrieval_report_path = self.output_dir / "retrieval_sanity.json"
        
        # Data storage
        self.embeddings: Optional[np.ndarray] = None
        self.metadata: Optional[Dict[str, Any]] = None
        self.chunks: Optional[List[Dict[str, Any]]] = None
        self.model: Optional[SentenceTransformer] = None
        
        # Persian legal keywords for sanity testing
        self.persian_keywords = [
            "Ù‡ÛŒØ¦Øª Ø¹Ù„Ù…ÛŒ",
            "ØªØ¨ØµØ±Ù‡", 
            "Ø¢ÛŒÛŒÙ†â€ŒÙ†Ø§Ù…Ù‡",
            "Ø¨ÙˆØ¯Ø¬Ù‡",
            "Ù‚Ø§Ù†ÙˆÙ†",
            "Ù…Ø§Ø¯Ù‡",
            "ÙØµÙ„",
            "Ø¨Ø®Ø´",
            "Ú©Ù…ÛŒØ³ÛŒÙˆÙ†",
            "Ø´ÙˆØ±Ø§",
            "Ù…Ø¬Ù„Ø³",
            "ÙˆØ²Ø§Ø±Øª",
            "Ø§Ø¯Ø§Ø±Ù‡",
            "Ø³Ø§Ø²Ù…Ø§Ù†",
            "Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡"
        ]
    
    def _load_data(self) -> None:
        """
        Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²
        Load required data
        """
        logger.info("Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²...")
        logger.info("Loading required data...")
        
        # Load embeddings
        if not self.embeddings_path.exists():
            raise FileNotFoundError(f"ÙØ§ÛŒÙ„ Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§ ÛŒØ§ÙØª Ù†Ø´Ø¯: {self.embeddings_path}")
        
        self.embeddings = np.load(self.embeddings_path)
        logger.info(f"Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯: Ø´Ú©Ù„ {self.embeddings.shape}")
        
        # Load metadata
        if not self.meta_path.exists():
            raise FileNotFoundError(f"ÙØ§ÛŒÙ„ Ù…ØªØ§Ø¯ÛŒØªØ§ÛŒ Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§ ÛŒØ§ÙØª Ù†Ø´Ø¯: {self.meta_path}")
        
        with open(self.meta_path, 'r', encoding='utf-8') as f:
            self.metadata = json.load(f)
        
        # Load chunks
        if not self.chunks_path.exists():
            raise FileNotFoundError(f"ÙØ§ÛŒÙ„ Ù‚Ø·Ø¹Ø§Øª ÛŒØ§ÙØª Ù†Ø´Ø¯: {self.chunks_path}")
        
        with open(self.chunks_path, 'r', encoding='utf-8') as f:
            chunks_data = json.load(f)
        
        if isinstance(chunks_data, dict):
            self.chunks = chunks_data.get('chunks', [])
        elif isinstance(chunks_data, list):
            self.chunks = chunks_data
        else:
            raise ValueError("ÙØ±Ù…Øª Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„ chunks.json")
        
        logger.info(f"Ù‚Ø·Ø¹Ø§Øª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯: {len(self.chunks)} Ù‚Ø·Ø¹Ù‡")
    
    def _load_model(self) -> SentenceTransformer:
        """
        Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ embedding Ø¨Ø±Ø§ÛŒ ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ Ø¬Ø³ØªØ¬Ùˆ
        Load embedding model for retrieval tests
        """
        if not HAS_SENTENCE_TRANSFORMERS:
            raise ImportError("Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ sentence-transformers Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª")
        
        try:
            logger.info(f"Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„: {self.model_name}")
            # Try to load from local cache first
            os.environ['TRANSFORMERS_OFFLINE'] = '1'
            model = SentenceTransformer(self.model_name, local_files_only=True)
            logger.info("Ù…Ø¯Ù„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø² Ú©Ø´ Ù…Ø­Ù„ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
            return model
        except Exception as e:
            logger.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ø§Ø² Ú©Ø´ Ù…Ø­Ù„ÛŒ: {str(e)}")
            try:
                # Try without offline mode
                if 'TRANSFORMERS_OFFLINE' in os.environ:
                    del os.environ['TRANSFORMERS_OFFLINE']
                model = SentenceTransformer(self.model_name)
                logger.info("Ù…Ø¯Ù„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø² Ø§ÛŒÙ†ØªØ±Ù†Øª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
                return model
            except Exception as e2:
                logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„: {str(e2)}")
                logger.warning("Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø¯ÙˆÙ† ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ Ø¬Ø³ØªØ¬Ùˆ...")
                return None
    
    def analyze_embeddings(self) -> Dict[str, Any]:
        """
        ØªØ¬Ø²ÛŒÙ‡ Ùˆ ØªØ­Ù„ÛŒÙ„ Ú©ÛŒÙÛŒØª Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§
        Analyze embedding quality
        """
        logger.info("Ø´Ø±ÙˆØ¹ ØªØ¬Ø²ÛŒÙ‡ Ùˆ ØªØ­Ù„ÛŒÙ„ Ú©ÛŒÙÛŒØª Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§...")
        logger.info("Starting embedding quality analysis...")
        
        report = {}
        
        # Basic dimensions and count
        report['vector_dimension'] = int(self.embeddings.shape[1])
        report['vector_count'] = int(self.embeddings.shape[0])
        
        # Calculate L2 norms
        l2_norms = np.linalg.norm(self.embeddings, axis=1)
        report['l2_norms'] = {
            'mean': float(np.mean(l2_norms)),
            'variance': float(np.var(l2_norms)),
            'std': float(np.std(l2_norms)),
            'min': float(np.min(l2_norms)),
            'max': float(np.max(l2_norms))
        }
        
        logger.info(f"L2 Ù†Ø±Ù…â€ŒÙ‡Ø§ - Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†: {report['l2_norms']['mean']:.4f}, ÙˆØ§Ø±ÛŒØ§Ù†Ø³: {report['l2_norms']['variance']:.4f}")
        
        # Find potential duplicates using cosine similarity
        logger.info("Ø¬Ø³ØªØ¬ÙˆÛŒ Ù‚Ø·Ø¹Ø§Øª Ù…Ø´Ø§Ø¨Ù‡ Ø¨Ø§ Ú©Ø³ÛŒÙ†ÙˆØ³ > 0.98...")
        duplicates = self._find_duplicate_candidates(threshold=0.98)
        report['duplicate_candidates'] = duplicates
        
        # Analyze chunk lengths
        logger.info("ØªØ¬Ø²ÛŒÙ‡ Ùˆ ØªØ­Ù„ÛŒÙ„ ØªÙˆØ²ÛŒØ¹ Ø·ÙˆÙ„ Ù‚Ø·Ø¹Ø§Øª...")
        length_distribution = self._analyze_chunk_lengths()
        report['chunk_length_distribution'] = length_distribution
        
        # Additional quality metrics
        report['embedding_stats'] = {
            'mean_magnitude': float(np.mean(l2_norms)),
            'embedding_density': float(np.mean(np.abs(self.embeddings))),
            'zero_vectors': int(np.sum(l2_norms < 1e-8)),
            'model_name': self.metadata.get('model_name', 'unknown')
        }
        
        report['analysis_metadata'] = {
            'analysis_time_utc': datetime.now(timezone.utc).isoformat(),
            'random_seed': self.random_seed,
            'chunks_md5': self.metadata.get('chunks_md5', ''),
            'embedding_creation_time': self.metadata.get('created_utc', '')
        }
        
        logger.info("ØªØ¬Ø²ÛŒÙ‡ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§ Ú©Ø§Ù…Ù„ Ø´Ø¯")
        logger.info("Embedding analysis completed")
        
        return report
    
    def _find_duplicate_candidates(self, threshold: float = 0.98) -> List[Dict[str, Any]]:
        """
        ÛŒØ§ÙØªÙ† Ù†Ø§Ù…Ø²Ø¯Ù‡Ø§ÛŒ Ù…Ø´Ø§Ø¨Ù‡ Ø¨Ø§ Ú©Ø³ÛŒÙ†ÙˆØ³ Ø¨Ø§Ù„Ø§
        Find duplicate candidates with high cosine similarity
        """
        duplicates = []
        
        # Normalize embeddings for cosine similarity
        normalized_embeddings = self.embeddings / np.linalg.norm(self.embeddings, axis=1, keepdims=True)
        
        # Calculate cosine similarity matrix (sample-based for efficiency)
        sample_size = min(500, len(self.embeddings))  # Sample for performance
        sample_indices = random.sample(range(len(self.embeddings)), sample_size)
        
        logger.info(f"Ø¨Ø±Ø±Ø³ÛŒ {sample_size} Ù†Ù…ÙˆÙ†Ù‡ Ø¨Ø±Ø§ÛŒ ÛŒØ§ÙØªÙ† Ù‚Ø·Ø¹Ø§Øª Ù…Ø´Ø§Ø¨Ù‡...")
        
        for i, idx_i in enumerate(sample_indices):
            if i % 100 == 0:
                logger.info(f"Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù†Ù…ÙˆÙ†Ù‡ {i}/{sample_size}")
            
            # Compare with all other embeddings
            similarities = np.dot(normalized_embeddings[idx_i], normalized_embeddings.T)
            high_sim_indices = np.where(similarities > threshold)[0]
            
            for idx_j in high_sim_indices:
                if idx_i != idx_j:  # Skip self-similarity
                    chunk_uid_i = self.metadata['chunk_uid_order'][idx_i] if idx_i < len(self.metadata['chunk_uid_order']) else f"idx_{idx_i}"
                    chunk_uid_j = self.metadata['chunk_uid_order'][idx_j] if idx_j < len(self.metadata['chunk_uid_order']) else f"idx_{idx_j}"
                    
                    duplicates.append({
                        'chunk_uid_1': chunk_uid_i,
                        'chunk_uid_2': chunk_uid_j,
                        'cosine_similarity': float(similarities[idx_j]),
                        'embedding_indices': [int(idx_i), int(idx_j)]
                    })
        
        # Remove duplicates and sort by similarity
        seen = set()
        unique_duplicates = []
        for dup in duplicates:
            # Create a unique key
            key = tuple(sorted([dup['chunk_uid_1'], dup['chunk_uid_2']]))
            if key not in seen:
                seen.add(key)
                unique_duplicates.append(dup)
        
        unique_duplicates.sort(key=lambda x: x['cosine_similarity'], reverse=True)
        
        logger.info(f"ÛŒØ§ÙØª Ø´Ø¯ {len(unique_duplicates)} Ø¬ÙØª Ù…Ø´Ø§Ø¨Ù‡ Ø¨Ø§ Ú©Ø³ÛŒÙ†ÙˆØ³ > {threshold}")
        
        return unique_duplicates[:20]  # Return top 20
    
    def _analyze_chunk_lengths(self) -> Dict[str, Any]:
        """
        ØªØ¬Ø²ÛŒÙ‡ Ùˆ ØªØ­Ù„ÛŒÙ„ ØªÙˆØ²ÛŒØ¹ Ø·ÙˆÙ„ Ù‚Ø·Ø¹Ø§Øª
        Analyze chunk length distribution
        """
        lengths = []
        
        for chunk in self.chunks:
            content = chunk.get('content', chunk.get('text', chunk.get('normalized_text', '')))
            char_count = len(content.strip())
            lengths.append(char_count)
        
        lengths = np.array(lengths)
        
        return {
            'mean_length': float(np.mean(lengths)),
            'median_length': float(np.median(lengths)),
            'std_length': float(np.std(lengths)),
            'min_length': int(np.min(lengths)),
            'max_length': int(np.max(lengths)),
            'percentiles': {
                '25th': float(np.percentile(lengths, 25)),
                '50th': float(np.percentile(lengths, 50)),
                '75th': float(np.percentile(lengths, 75)),
                '90th': float(np.percentile(lengths, 90)),
                '95th': float(np.percentile(lengths, 95))
            },
            'total_chunks': len(lengths),
            'empty_chunks': int(np.sum(lengths == 0))
        }
    
    def perform_retrieval_sanity_test(self) -> Dict[str, Any]:
        """
        Ø§Ù†Ø¬Ø§Ù… ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ Ø¹Ù‚Ù„ÛŒ Ø¬Ø³ØªØ¬Ùˆ
        Perform retrieval sanity tests
        """
        logger.info("Ø´Ø±ÙˆØ¹ ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ Ø¹Ù‚Ù„ÛŒ Ø¬Ø³ØªØ¬Ùˆ...")
        logger.info("Starting retrieval sanity tests...")
        
        # Load model for query encoding
        if not self.model:
            self.model = self._load_model()
        
        # If model loading failed, return a placeholder report
        if not self.model:
            logger.warning("Ù…Ø¯Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯ØŒ ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ Ø¬Ø³ØªØ¬Ùˆ Ù‚Ø§Ø¨Ù„ Ø§Ù†Ø¬Ø§Ù… Ù†ÛŒØ³Øª")
            logger.warning("Model not loaded, retrieval tests cannot be performed")
            return {
                'test_queries': [],
                'backend_info': {
                    'type': self.backend,
                    'model_name': self.model_name,
                    'total_vectors': self.embeddings.shape[0] if self.embeddings is not None else 0,
                    'status': 'model_loading_failed'
                },
                'test_metadata': {
                    'test_time_utc': datetime.now(timezone.utc).isoformat(),
                    'random_seed': self.random_seed,
                    'keywords_tested': 0,
                    'error': 'Model loading failed - network or cache issues'
                }
            }
        
        # Prepare backend for search
        try:
            search_backend = self._prepare_search_backend()
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù† Ø¬Ø³ØªØ¬Ùˆ: {str(e)}")
            return {
                'test_queries': [],
                'backend_info': {
                    'type': self.backend,
                    'model_name': self.model_name,
                    'total_vectors': self.embeddings.shape[0] if self.embeddings is not None else 0,
                    'status': 'backend_preparation_failed'
                },
                'test_metadata': {
                    'test_time_utc': datetime.now(timezone.utc).isoformat(),
                    'random_seed': self.random_seed,
                    'keywords_tested': 0,
                    'error': f'Backend preparation failed: {str(e)}'
                }
            }
        
        results = {
            'test_queries': [],
            'backend_info': {
                'type': self.backend,
                'model_name': self.model_name,
                'total_vectors': self.embeddings.shape[0]
            },
            'test_metadata': {
                'test_time_utc': datetime.now(timezone.utc).isoformat(),
                'random_seed': self.random_seed,
                'keywords_tested': len(self.persian_keywords)
            }
        }
        
        # Test each keyword
        for i, keyword in enumerate(self.persian_keywords[:10]):  # Test first 10 keywords
            logger.info(f"ØªØ³Øª Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡: {keyword} ({i+1}/{min(10, len(self.persian_keywords))})")
            
            try:
                # Encode query
                query_embedding = self.model.encode([keyword], convert_to_numpy=True)[0]
                
                # Perform search
                top_results = self._search_with_backend(search_backend, query_embedding, k=5)
                
                # Analyze results
                query_result = {
                    'query': keyword,
                    'top_results': top_results,
                    'analysis': self._analyze_retrieval_results(keyword, top_results)
                }
                
                results['test_queries'].append(query_result)
                
            except Exception as e:
                logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ³Øª Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡ '{keyword}': {str(e)}")
                results['test_queries'].append({
                    'query': keyword,
                    'error': str(e),
                    'top_results': [],
                    'analysis': {'error': True}
                })
        
        logger.info("ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ Ø¹Ù‚Ù„ÛŒ Ø¬Ø³ØªØ¬Ùˆ Ú©Ø§Ù…Ù„ Ø´Ø¯")
        logger.info("Retrieval sanity tests completed")
        
        return results
    
    def _prepare_search_backend(self):
        """
        Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù† Ø¬Ø³ØªØ¬Ùˆ
        Prepare search backend
        """
        if self.backend == 'faiss':
            return self._prepare_faiss_backend()
        elif self.backend == 'chroma':
            return self._prepare_chroma_backend()
        else:
            raise ValueError(f"Ù¾Ø´ØªÛŒØ¨Ø§Ù† Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù†Ø´Ø¯Ù‡: {self.backend}")
    
    def _prepare_faiss_backend(self):
        """Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ FAISS"""
        if not HAS_FAISS:
            raise ImportError("Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ faiss Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª")
        
        faiss_dir = self.vector_db_dir / "faiss"
        index_path = faiss_dir / "faiss.index"
        mapping_path = faiss_dir / "mapping.json"
        
        if not index_path.exists():
            raise FileNotFoundError(f"ÙØ§ÛŒÙ„ ÙÙ‡Ø±Ø³Øª FAISS ÛŒØ§ÙØª Ù†Ø´Ø¯: {index_path}")
        
        # Load index
        index = faiss.read_index(str(index_path))
        
        # Load mapping
        mapping = {}
        if mapping_path.exists():
            with open(mapping_path, 'r', encoding='utf-8') as f:
                mapping = json.load(f)
        
        return {'index': index, 'mapping': mapping, 'type': 'faiss'}
    
    def _prepare_chroma_backend(self):
        """Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Chroma"""
        if not HAS_CHROMA:
            raise ImportError("Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ chromadb Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª")
        
        chroma_dir = self.vector_db_dir / "chroma"
        
        if not chroma_dir.exists():
            raise FileNotFoundError(f"Ù¾ÙˆØ´Ù‡ Chroma ÛŒØ§ÙØª Ù†Ø´Ø¯: {chroma_dir}")
        
        # Create client
        client = chromadb.PersistentClient(
            path=str(chroma_dir),
            settings=Settings(anonymized_telemetry=False, is_persistent=True)
        )
        
        # Get collection
        collection = client.get_collection("legal_chunks")
        
        return {'client': client, 'collection': collection, 'type': 'chroma'}
    
    def _search_with_backend(self, backend, query_embedding: np.ndarray, k: int = 5) -> List[Dict[str, Any]]:
        """
        Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†
        Search using backend
        """
        if backend['type'] == 'faiss':
            return self._search_faiss(backend, query_embedding, k)
        elif backend['type'] == 'chroma':
            return self._search_chroma(backend, query_embedding, k)
        else:
            raise ValueError(f"Ù†ÙˆØ¹ Ù¾Ø´ØªÛŒØ¨Ø§Ù† Ù†Ø§Ù…Ø¹ØªØ¨Ø±: {backend['type']}")
    
    def _search_faiss(self, backend, query_embedding: np.ndarray, k: int) -> List[Dict[str, Any]]:
        """Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± FAISS"""
        index = backend['index']
        mapping = backend['mapping']
        
        # Normalize query embedding
        query_embedding = query_embedding.astype(np.float32)
        query_embedding = query_embedding / np.linalg.norm(query_embedding)
        
        # Search
        scores, indices = index.search(query_embedding.reshape(1, -1), k)
        
        results = []
        for i, (score, idx) in enumerate(zip(scores[0], indices[0])):
            if idx == -1:  # FAISS returns -1 for invalid results
                continue
            
            chunk_uid = mapping.get(str(idx), f"idx_{idx}")
            
            # Find chunk data
            chunk_data = None
            for chunk in self.chunks:
                if chunk.get('uid', chunk.get('chunk_uid', '')) == chunk_uid:
                    chunk_data = chunk
                    break
            
            result = {
                'rank': i + 1,
                'chunk_uid': chunk_uid,
                'similarity_score': float(score),
                'chunk_data': chunk_data
            }
            results.append(result)
        
        return results
    
    def _search_chroma(self, backend, query_embedding: np.ndarray, k: int) -> List[Dict[str, Any]]:
        """Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± Chroma"""
        collection = backend['collection']
        
        # Search
        search_results = collection.query(
            query_embeddings=[query_embedding.tolist()],
            n_results=k,
            include=['documents', 'metadatas', 'distances']
        )
        
        results = []
        if search_results['ids'] and search_results['ids'][0]:
            for i, (chunk_id, document, metadata, distance) in enumerate(zip(
                search_results['ids'][0],
                search_results['documents'][0],
                search_results['metadatas'][0],
                search_results['distances'][0]
            )):
                result = {
                    'rank': i + 1,
                    'chunk_uid': chunk_id,
                    'similarity_score': 1.0 - distance,  # Convert distance to similarity
                    'document_content': document,
                    'metadata': metadata
                }
                results.append(result)
        
        return results
    
    def _analyze_retrieval_results(self, query: str, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        ØªØ¬Ø²ÛŒÙ‡ Ùˆ ØªØ­Ù„ÛŒÙ„ Ù†ØªØ§ÛŒØ¬ Ø¬Ø³ØªØ¬Ùˆ
        Analyze retrieval results
        """
        analysis = {
            'query_found_in_results': 0,
            'avg_similarity': 0.0,
            'result_count': len(results),
            'has_relevant_results': False
        }
        
        if not results:
            return analysis
        
        # Calculate average similarity
        similarities = [r.get('similarity_score', 0) for r in results]
        analysis['avg_similarity'] = float(np.mean(similarities)) if similarities else 0.0
        
        # Check if query appears in results
        query_lower = query.lower()
        for result in results:
            content = ""
            if 'chunk_data' in result and result['chunk_data']:
                content = result['chunk_data'].get('content', 
                    result['chunk_data'].get('text', 
                        result['chunk_data'].get('normalized_text', '')
                    )
                )
            elif 'document_content' in result:
                content = result['document_content']
            
            if query_lower in content.lower():
                analysis['query_found_in_results'] += 1
        
        # Determine if results are relevant (similarity > 0.3 or query found)
        analysis['has_relevant_results'] = (
            analysis['avg_similarity'] > 0.3 or 
            analysis['query_found_in_results'] > 0
        )
        
        return analysis
    
    def generate_persian_summary(self, embedding_report: Dict[str, Any], retrieval_report: Dict[str, Any]) -> str:
        """
        ØªÙˆÙ„ÛŒØ¯ Ø®Ù„Ø§ØµÙ‡ ÙØ§Ø±Ø³ÛŒ
        Generate Persian summary
        """
        # Embedding analysis summary
        duplicate_count = len(embedding_report.get('duplicate_candidates', []))
        total_vectors = embedding_report.get('vector_count', 0)
        duplicate_percentage = (duplicate_count / total_vectors * 100) if total_vectors > 0 else 0
        
        # Retrieval analysis summary
        successful_queries = 0
        total_queries = len(retrieval_report.get('test_queries', []))
        retrieval_status = retrieval_report.get('backend_info', {}).get('status', 'unknown')
        
        if retrieval_status == 'model_loading_failed':
            success_rate = -1  # Indicate test failed
        elif total_queries > 0:
            for query_result in retrieval_report.get('test_queries', []):
                if query_result.get('analysis', {}).get('has_relevant_results', False):
                    successful_queries += 1
            success_rate = (successful_queries / total_queries * 100)
        else:
            success_rate = 0
        
        summary = f"""Ù†ØªØ§ÛŒØ¬ Ø³Ù†Ø¬Ø´ Ú©ÛŒÙÛŒØª Ø³ÛŒØ³ØªÙ… RAG:

ğŸ“Š Ø¢Ù…Ø§Ø± Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§:
- ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§: {total_vectors:,}
- Ø§Ø¨Ø¹Ø§Ø¯ Ø¨Ø±Ø¯Ø§Ø±: {embedding_report.get('vector_dimension', 0)}
- Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù†Ø±Ù… L2: {embedding_report.get('l2_norms', {}).get('mean', 0):.4f}

ğŸ” ØªØ´Ø®ÛŒØµ ØªÚ©Ø±Ø§Ø±ÛŒ:
- {duplicate_percentage:.1f}Ùª Ù‚Ø·Ø¹Ø§Øª Ù…Ø´Ø§Ø¨Ù‡ Ø¨Ø³ÛŒØ§Ø± Ø¨Ø§Ù„Ø§ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯
- {duplicate_count} Ø¬ÙØª Ù…Ø´Ø§Ø¨Ù‡ Ø¨Ø§ Ú©Ø³ÛŒÙ†ÙˆØ³ > Û°.Û¹Û¸

ğŸ“ ØªÙˆØ²ÛŒØ¹ Ø·ÙˆÙ„ Ù‚Ø·Ø¹Ø§Øª:
- Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø·ÙˆÙ„: {embedding_report.get('chunk_length_distribution', {}).get('mean_length', 0):.0f} Ú©Ø§Ø±Ø§Ú©ØªØ±
- Ø­Ø¯Ø§Ú©Ø«Ø± Ø·ÙˆÙ„: {embedding_report.get('chunk_length_distribution', {}).get('max_length', 0):,} Ú©Ø§Ø±Ø§Ú©ØªØ±

ğŸ” Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¬Ø³ØªØ¬Ùˆ:
{f'- Ù†Ø±Ø® Ù…ÙˆÙÙ‚ÛŒØª: {success_rate:.1f}Ùª ({successful_queries}/{total_queries} Ù¾Ø±Ø³â€ŒÙˆØ¬Ùˆ)' if success_rate >= 0 else '- âš ï¸ ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ Ø¬Ø³ØªØ¬Ùˆ Ù‚Ø§Ø¨Ù„ Ø§Ù†Ø¬Ø§Ù… Ù†Ø¨ÙˆØ¯ (Ù…Ø´Ú©Ù„ Ø´Ø¨Ú©Ù‡/Ù…Ø¯Ù„)'}
- Ù¾Ø´ØªÛŒØ¨Ø§Ù† Ù…ÙˆØ±Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡: {retrieval_report.get('backend_info', {}).get('type', 'Ù†Ø§Ù…Ø´Ø®Øµ')}

âš ï¸ Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ:
{
    'âœ… Ú©ÛŒÙÛŒØª Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§ Ù‚Ø§Ø¨Ù„ Ù‚Ø¨ÙˆÙ„' if duplicate_percentage < 5 else 'âš ï¸ ØªØ¹Ø¯Ø§Ø¯ Ø²ÛŒØ§Ø¯ Ù‚Ø·Ø¹Ø§Øª Ù…Ø´Ø§Ø¨Ù‡'
}{
    ' | Ø¬Ø³ØªØ¬Ùˆ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø±Ø±Ø³ÛŒ' if success_rate == -1 else 
    ' | Ø¬Ø³ØªØ¬Ùˆ Ù…Ù†Ø§Ø³Ø¨' if success_rate > 60 else 
    ' | Ø¬Ø³ØªØ¬Ùˆ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯' if success_rate >= 0 else ''
}

ğŸ“… Ø²Ù…Ø§Ù† Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ: {datetime.now().strftime('%Y/%m/%d - %H:%M')}
ğŸ”¢ Ø¨Ø°Ø± ØªØµØ§Ø¯ÙÛŒ: {self.random_seed}
"""
        
        return summary
    
    def run_quality_evaluation(self) -> None:
        """
        Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø§Ù…Ù„ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú©ÛŒÙÛŒØª
        Run complete quality evaluation
        """
        try:
            logger.info("Ø´Ø±ÙˆØ¹ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú©ÛŒÙÛŒØª Ø³ÛŒØ³ØªÙ… RAG...")
            logger.info("Starting RAG system quality evaluation...")
            
            # Load data
            self._load_data()
            
            # Analyze embeddings
            logger.info("Ù…Ø±Ø­Ù„Ù‡ Û±: ØªØ¬Ø²ÛŒÙ‡ Ùˆ ØªØ­Ù„ÛŒÙ„ Ú©ÛŒÙÛŒØª Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§")
            embedding_report = self.analyze_embeddings()
            
            # Save embedding report
            with open(self.embedding_report_path, 'w', encoding='utf-8') as f:
                json.dump(embedding_report, f, indent=2, ensure_ascii=False)
            logger.info(f"Ú¯Ø²Ø§Ø±Ø´ Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {self.embedding_report_path}")
            
            # Perform retrieval tests
            logger.info("Ù…Ø±Ø­Ù„Ù‡ Û²: ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ Ø¹Ù‚Ù„ÛŒ Ø¬Ø³ØªØ¬Ùˆ")
            retrieval_report = self.perform_retrieval_sanity_test()
            
            # Save retrieval report
            with open(self.retrieval_report_path, 'w', encoding='utf-8') as f:
                json.dump(retrieval_report, f, indent=2, ensure_ascii=False)
            logger.info(f"Ú¯Ø²Ø§Ø±Ø´ Ø¬Ø³ØªØ¬Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {self.retrieval_report_path}")
            
            # Generate Persian summary
            logger.info("Ù…Ø±Ø­Ù„Ù‡ Û³: ØªÙˆÙ„ÛŒØ¯ Ø®Ù„Ø§ØµÙ‡ ÙØ§Ø±Ø³ÛŒ")
            summary = self.generate_persian_summary(embedding_report, retrieval_report)
            
            # Print summary
            print("\n" + "="*60)
            try:
                print(summary)
            except UnicodeEncodeError:
                # Fallback for console encoding issues
                print(summary.encode('utf-8', errors='replace').decode('utf-8'))
            print("="*60)
            
            logger.info("Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú©ÛŒÙÛŒØª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ú©Ø§Ù…Ù„ Ø´Ø¯!")
            logger.info("Quality evaluation completed successfully!")
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú©ÛŒÙÛŒØª: {str(e)}")
            logger.error(f"Error in quality evaluation: {str(e)}")
            raise
    
    def run(self) -> None:
        """
        Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø§Ù…Ù„ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ
        Run the complete evaluation process
        """
        self.run_quality_evaluation()


def load_config() -> Dict[str, Any]:
    """
    Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§Ø² ÙØ§ÛŒÙ„ Ú©Ø§Ù†ÙÛŒÚ¯
    Load configuration from config file
    """
    config_paths = [
        "config.json",
        "data/config.json", 
        "phase_3_rag/config.json"
    ]
    
    for config_path in config_paths:
        if os.path.exists(config_path):
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ø§Ù†ÙÛŒÚ¯ Ø§Ø² {config_path}: {e}")
                continue
    
    # Default configuration
    logger.info("Ø§Ø² ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯")
    
    return {
        "rag": {
            "embedding_model": "paraphrase-multilingual-MiniLM-L12-v2",
            "index_backend": "faiss"
        },
        "random_seed": 42
    }


def main():
    """
    ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø³ØªÙ‚Ù„
    Main function for standalone execution
    """
    try:
        config = load_config()
        evaluator = QualityEvaluator(config)
        evaluator.run()
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ: {str(e)}")
        logger.error(f"General error: {str(e)}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())